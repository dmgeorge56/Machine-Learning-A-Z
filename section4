#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Feb 18 20:02:09 2017

@author: dana
"""

##simple linear regression
"""OLS:
   sum (y - y^)^2 -> min
   best fit line = the line that minimizes the sum of the squares
"""

##Part 1: Data Preprocessing
##Importing the Libraries
import numpy as np ##for math stuffz
import matplotlib.pyplot as plt ##plot charts
import pandas as pd ##to import and manage datasets
import os as os ##to check working directory

##Set working directory
os.getcwd()
os.chdir('/Users/Dana/Spyder/Gits/Machine-Learning-A-Z/Simple_Linear_Regression')

##Importing the dataset
dataset = pd.read_csv('Salary_Data.csv')

##distingiush independent variable matrix
x = dataset.iloc[:,:-1].values
##distinguish dependent variable matrix
y = dataset.iloc[:,1].values

##Splitting the data into training set and test set
#from sklearn.cross_validation import train_test_split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3, random_state=0)

##Feature Scaling
##age and income need to be on the same scale, because
##a lot of ML models are based on the euclidean distances 
##the squared root of the sum of the squared coordinates
##if the x coordinate is age, and y is salary, the euclidian distance will be
##dominated by salary
##so need to put the two on the same scale
##if not, the ML will basically be that the smaller values do not exist, and will 
##be dominated by the larger number
##two ways to feature scale:
    ##1. Standardization:
        #xstand = (x-meanx)/(sd(x)))
    ##2. Normalization:
        #xnorm = (x-minx)/(max(x)-min(x))
        
"""from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler() #object
x_train= sc_x.fit_transform(x_train) #fit to object
x_test= sc_x.transform(x_test)"""

##fitting simple linear regression to the training set
from sklearn.linear_model import LinearRegression
regressor = LinearRegression() ##make a machine to learn on the training set
regressor.fit(x_train, y_train) ##fit the machine to the training data
##its learning experience can then predict y for the test data

##predict the test set results
"""
1. create vector of predicted salary values
2.
3.
4.
"""
y_pred = regressor.predict(x_test)
                      
##visualising the traing set results
##plot observation points and regression line
plt.scatter(x_train, y_train, color='red')
plt.plot(x_train, regressor.predict(x_train), color='blue')
plt.title('Salary vs Experience (training set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()

plt.scatter(x_test, y_test, color='red')
plt.plot(x_train, regressor.predict(x_train), color='blue')
plt.title('Salary vs Experience (test set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()















